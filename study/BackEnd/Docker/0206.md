# Apache Kafka
대량의 데이터를 실시간으로 안전하게 전달·저장하는 중간 허브
메세징프로그램(공유해야하는 데이터 싱크, 이메일, 알림설정 등등 실행가능)

## 흐름도
![alt text](image-2.png)
producer가 broker에 메세지 전달
이 Broker가 kafka, pd&cs가 개발자가 만든 것들
컨슈머가 메세지 하나를 읽음 -> 처리 완료되면 브로커가 삭제함

## CMD에서 kafka 실행하기
kafka 명령어는 window에서 바로 실행할 수 없음
-> 환경변수 설정
-> 시스템 변수의 Path 
-> 편집 눌러서 새로 만들기
-> 내가 kafka Binary 다운로드한 경로 그대로 복붙해서 생성
-> cmd에 들어가서 kafka 명령어 실행하면 실행 됨!

1. Kafka 이미지 받기
```
docker pull apache/kafka:4.0.1
```

2. docker container 접속하기
```
docker exec -it kafka /bin/bash
```

3. kafka 파일 위치로 접근하기
```
cd /opt/kafka/bin
```

4. 토픽 만들기
```
./kafka-topics.sh --bootstrap-server localhost:9092 --create --topic my-topic
```

5. 토픽 목록 보기
```
./kafka-topics.sh --bootstrap-server localhost:9092 --list
```

6. 토픽 목록 삭제하기
```
./kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic my-topic
```

7. 토픽에 내용물 넣기
```
./kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test
```
- producer로 들어가면 보내짐
```
./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
```
- consumer로 들어가면 보낸 내용 받을 수 있고 뒤에 --from-beginning이 있으면 첫 내용부터, 없으면 접속 시점부터 보여짐


## python에서 kafka 실행하기
```main.py
from kafka import KafkaProducer

pd = KafkaProducer(bootstrap_servers="localhost:9092")

pd.send('test',b'loveyou')
#('토픽이름', b'메세지')
# producer&consumer의 토픽 이름이 같아야 확인이 가능함
pd.flush()
# 보낸다는 함수
```
```받을쪽.py
from kafka import KafkaConsumer

cs=KafkaConsumer('test',bootstrap_servers=["localhost:9092"])

for msg in cs:
    print(msg.value)
```

그리고 각각 터미널 열어 각 파일 실행해주기 => main.py의 메세지 바꿔서 실행할 때 마다 consumer 터미널에 내용이 찍힘

[Kafka Tutorial PDF](./Kafka%20Python%20Tutorial.pdf)